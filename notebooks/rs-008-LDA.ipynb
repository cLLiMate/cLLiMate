{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "nltk.download(\"wordnet\", quiet=True)\n",
    "nltk.download(\"omw-1.4\", quiet=True)\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        \n",
    "        if token not in stopwords.words('english') and len(token) > 3:\n",
    "            \n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.read_parquet(\"../data/processed/news-consolidated-v1.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = total_data[\"headline\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(processed)\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1)], [(4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1)], [(10, 1), (11, 1), (12, 1), (13, 1), (14, 1)], [(15, 1), (16, 1), (17, 1), (18, 1)], [(19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1)]]\n"
     ]
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed]\n",
    "print(bow_corpus[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, \n",
    "                                       num_topics=10, \n",
    "                                       id2word = dictionary, \n",
    "                                       passes = 2, \n",
    "                                       workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.035*\"futur\" + 0.025*\"ocean\" + 0.020*\"look\" + 0.017*\"impact\" + 0.016*\"farmer\" + 0.012*\"mean\" + 0.012*\"drought\" + 0.011*\"seismic\" + 0.011*\"polit\" + 0.011*\"atmospher\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.028*\"report\" + 0.027*\"carbon\" + 0.018*\"north\" + 0.018*\"temperatur\" + 0.015*\"fire\" + 0.014*\"record\" + 0.014*\"ocean\" + 0.014*\"extrem\" + 0.014*\"scientist\" + 0.013*\"earthquak\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.044*\"call\" + 0.025*\"health\" + 0.023*\"system\" + 0.016*\"nation\" + 0.016*\"batteri\" + 0.014*\"river\" + 0.013*\"home\" + 0.013*\"elect\" + 0.012*\"influenc\" + 0.012*\"pacif\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.019*\"like\" + 0.018*\"countri\" + 0.014*\"show\" + 0.013*\"need\" + 0.012*\"atlant\" + 0.012*\"citi\" + 0.011*\"structur\" + 0.011*\"say\" + 0.011*\"sustain\" + 0.011*\"emerg\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.030*\"emiss\" + 0.027*\"effect\" + 0.018*\"model\" + 0.017*\"busi\" + 0.015*\"make\" + 0.013*\"scale\" + 0.012*\"studi\" + 0.012*\"carbon\" + 0.011*\"coal\" + 0.011*\"use\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.032*\"action\" + 0.024*\"long\" + 0.016*\"term\" + 0.014*\"social\" + 0.014*\"economi\" + 0.014*\"biden\" + 0.013*\"break\" + 0.012*\"cycl\" + 0.012*\"environ\" + 0.012*\"media\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.048*\"global\" + 0.033*\"govern\" + 0.032*\"warm\" + 0.017*\"product\" + 0.011*\"drive\" + 0.010*\"food\" + 0.010*\"arctic\" + 0.010*\"cost\" + 0.009*\"say\" + 0.009*\"reveal\"\n",
      "\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.021*\"analysi\" + 0.018*\"earth\" + 0.016*\"land\" + 0.016*\"human\" + 0.015*\"deep\" + 0.014*\"plan\" + 0.013*\"commun\" + 0.013*\"water\" + 0.011*\"public\" + 0.011*\"manag\"\n",
      "\n",
      "\n",
      "Topic: 8 \n",
      "Words: 0.042*\"water\" + 0.015*\"organ\" + 0.015*\"soil\" + 0.014*\"surfac\" + 0.014*\"variabl\" + 0.013*\"reduc\" + 0.013*\"open\" + 0.012*\"save\" + 0.011*\"lead\" + 0.010*\"could\"\n",
      "\n",
      "\n",
      "Topic: 9 \n",
      "Words: 0.046*\"australia\" + 0.025*\"china\" + 0.020*\"trump\" + 0.015*\"solar\" + 0.014*\"deal\" + 0.011*\"cell\" + 0.011*\"say\" + 0.011*\"world\" + 0.010*\"south\" + 0.010*\"concern\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics():\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a3870566885d8713b456c7b616bb4ec819c6611b841c812a534b80b621588a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
